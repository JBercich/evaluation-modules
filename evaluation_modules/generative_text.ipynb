{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Modules - Generative Text\n",
    "\n",
    "This notebook runs through ideation for evaluation modules of generative text models. This will assume black-box evaluation environment knowing only input sentences, $S_{in}^{(i)} = (W_{in,1},...,W_{in,n})$, and respective model outputs, $S_{out}^{(i)} = (W_{out,1},...,W_{out,m})$. Evaluation modules will take a sequence of sentence pairs $\\mathbb{D}_{N \\times 2} = ((S_{in}^{(1)}, S_{out}^{(1)}),...,(S_{in}^{(N)}, S_{out}^{(N)}))$. The output of each evaluation metric is determined by what it is evaluated and changes per each."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beyond this type of model, the category of text generation also determines how it can be evaluated. The classes of generative contexts being assessed will be specified accordingly falling in the following areas:\n",
    "\n",
    "- Natural Language Generation (output analysis)\n",
    "    - Text summarisation\n",
    "    - Chatbot and ongoing dialog (question answering)\n",
    "- Natural Language Understanding (input analysis)\n",
    "    - Machine logic and language translation\n",
    "    - Multimedia translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
